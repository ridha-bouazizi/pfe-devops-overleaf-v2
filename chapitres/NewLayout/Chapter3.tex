\graphicspath{{./assets/}}
\setcounter{mtc}{3}
\chapter{2nd Sprint: Continuous integration and delivery }
\fancyhead[R]{\ungaramond\small\textbf{Chapter III.  2nd Sprint: Continuous integration and delivery }}

\minitoc
\newpage
\section*{Introduction}
Deploying a CI/CD platform is essential for modern software development as it enables developers to automate and streamline the software development lifecycle from code to production. 

In this chapter, we will discuss the process of deploying a comprehensive CI/CD platform that contains Jenkins as a CI/CD orchestrator, a SonarQube cluster for code quality and ArgoCD for continuous deployment. 

Firstly, we will go over the sprint backlog for this chapter. 

Then, we will provide an overview of the different tools and technologies that will be used in this chapter, including Jenkins, SonarQube, ArgoCD and other tools. 

Lastly, we will cover the step-by-step process of deploying the CI/CD platform.

\section{Sprint backlog :}

\begin{longtable}[H]{|m{1.5cm}|m{3cm}|m{1.5cm}|m{9cm}|}
\hline
{\textbf{Epic ID}} & {\textbf{Epic}} & {\textbf{Story ID}} & {\textbf{Story}}\\
\hline
1  & Self-hosting the ci/cd platform tools.  &  1.1	 & Setting up the CI/CD orchestrator.\\
\cline{3-4}
& & 1.2 & Setting up the container image builder. \\
\cline{3-4}
& & 1.3	& Setting up the code quality gate. \\
\cline{3-4}
& & 1.4	& Setting up the continuous delivery controller. \\
\cline{3-4}
\hline
2  & Setting up a GitOPS compliant CI/CD workflow for the applications in development.  &  2.1	 & Setting up the CI/CD orchestrator.\\
\cline{3-4}
& & 2.2 & SCM restructuring and code adaptation. \\
\cline{3-4}
& & 2.3	& Preparing container images for the different workloads in development.  \\
\cline{3-4}
& & 2.4	& Developing GitOPS oriented pipelines for the build, scan, and deliver phases in the various environments.  \\
\cline{3-4}
\hline
\caption{2nd Sprint Backlog}
\end{longtable}

\section{Components of the CI/CD platform }

\subsection{The database storage backend }

When deploying databases like PostgreSQL, Redis, and MongoDB on Kubernetes, it is important to consider high availability and scalability as critical factors. 

\subsubsection{Activity diagram for deploying the database storage backend }
\begin{figure}[H]\centering
\includegraphics[width=0.75\textwidth,angle=00]{assets/f35.png}
\caption{Activity diagram for deploying the database storage backend}
\label{fig:Activity diagram for deploying the database storage backend}
\end{figure}

\subsubsection{Replicated MongoDB }

MongoDB is a popular NoSQL database that supports horizontal scaling through sharding and replication.

Using a Kubernetes StatefulSet, we deployed multiple MongoDB instances in a replicated configuration and configured MongoDB replication for data synchronization.

The following figure illustrates the workloads put in place for the replicated mongodb cluster: 


\begin{figure}[H]\centering
\includegraphics[width=0.7\textwidth,angle=00]{assets/f36.png}
\caption{MongoDB Workloads }
\label{fig:MongoDB Workloads}
\end{figure}

With this setup, we obtained a highly available and scalable MongoDB database infrastructure for your containerized applications. 

\subsubsection{HA PostgreSQL }

Highly Available (HA) PostgreSQL on Kubernetes involves deploying multiple PostgreSQL instances that are managed by the replication middleware pgpool and are configured in a primary-standby replication configuration.

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f37.png}
\caption{HA PostgreSQL Workloads}
\label{fig:f37}
\end{figure}

This configuration ensures that one PostgreSQL instance always serves as the primary node that accepts all writes and updates, while the other instances act as standby nodes that replicate data from the primary node.

\newpage

\subsection{The artifact registry }

In a CI/CD platform, having an artifact registry is necessary to allows users to store, sign, and scan container images for vulnerabilities. This has been tackled using harbor. It also provides features such as user management, access control, and replication for distributing images across multiple registry instances. 

\begin{figure}[H]\centering
\includegraphics[width=0.85\textwidth,angle=00]{assets/f39.png}
\caption{diagram for deploying the artifact registry }
\label{fig:diagram for deploying the artifact registry}
\end{figure}

The following is an illustration on the deployed services for container image storage: 
\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f40.png}
\caption{deployed services}
\label{fig:Deployed services}
\end{figure}

\subsection{The code quality gate}

Software development is a complex and iterative process, and it is important to have tools that can help identify and address issues in the codebase as early as possible. 

\begin{figure}[H]\centering
\includegraphics[width=0.6\textwidth,angle=00]{assets/f41.png}
\caption{Activity diagram for deploying the code quality gate}
\label{fig:Activity diagram for deploying the code quality gate}
\end{figure}

SonarQube is a powerful code quality and security analysis tool that can be integrated with Kubernetes to help ensure that the code running in your Kubernetes environment is of high quality and secure.

Using the “ansible.builtin.uri” module, a POST request is sent to the SonarQube api to change the default admin password and generate a global token to be used by the cicd orchestrator. This token is then stored in a Kubernetes secret.

\subsection{CD/CD controller }

For the continuous deployment and continuous delivery aspect of our pipelines, we chose to use ArgoCD. 

Our CD/CD controller is characterized by a GitOps-based approach, utilizing GitLab as our preferred source code management system.

With automated deployments triggered by changes in respective Git repositories, manual deployments are eliminated, ensuring continuous updates. Employing declarative configuration management, we define the desired state of Kubernetes workloads in a configuration file, which is then enforced by ArgoCD. 

Additionally, ArgoCD offers a web-based interface to monitor deployed workloads and their synchronization status. 

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f43.png}
\caption{ AgroCD interface }
\label{fig:AgroCD interface}
\end{figure}

With declarative configuration management and ArgoCD's web-based interface, monitoring and maintaining deployed workloads become streamlined and efficient.

\newpage

\subsection{CI/CD orchestrator }

Jenkins, our CI/CD orchestrator of choice, provides a wide range of features and plugins that can be used to automate various stages of the software development process, including building, testing, and deploying applications. The following is the activity diagram for deploying it. 

 
\subsubsection{UML Design: Activity diagram for deploying the CI/CD orchestrator components : }

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f44.png}
\caption{Activity diagram for deploying the CI/CD orchestrator components}
\label{fig:Activity diagram for deploying the CI/CD orchestrator components}
\end{figure}
 
\subsubsection{The personalized jenkins container image: }

As a CI/CD orchestrator, Jenkins acts as a central hub that integrates with various tools and systems involved in the software development pipeline. The container image for this deployment is prepackaged with the initial configuration of the various cloud providers we are using, the server tokens and access credentials. Thus, the container image is ready to go as soon as it is deployed. The resulting Dockefile is as follows : 

\begin{listing}[H]
    \inputminted{Dockerfile}{codeListing/jenkins_Dockerfile}
    \caption{Jenkins Dockerfile}
    \label{lst:Jenkins Dockerfile}
\end{listing}

\subsubsection{The Docker in Docker container image: }

For building container images for the application under development, a technique that allows running Docker commands within a Docker container is used. To enable DinD, a Docker image is created with Docker installed inside it. Furthermore, authentication to the private registry is streamlined into the container execution. The following is the resulting Dockerfile: 

\begin{listing}[H]
    \inputminted{Dockerfile}{codeListing/dind-Dockerfile}
    \caption{Dind Dockerfile}
    \label{lst:Dind Dockerfile}
\end{listing}


\section{CI/CD Workflows}

\subsection{UML Design: Activity diagram for the CI/CD workflows } 

In the previous chapter, various CI/CD tools have been self-hosted in a complementary manner. Taking advantage of these tools, we are aiming to provide a reliable workflow to funnel the developed workloads through the various steps of code analysis, containerized artifact building, and deployment in various environments.  

 

The following is an activity diagram underlining the various interfaces, actors, and actions of these processes: 

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f45.png}
\caption{ Activity diagram for the CI/CD workflows}
\label{fig:Activity diagram for the CI/CD workflows}
\end{figure}

\subsection{UML Design: Sequence diagram of the CI/CD workflow }

Next, let’s look at the sequence diagram for the CI/CD workflow: 
\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f46.png}
\caption{ Sequence diagram of the CI/CD workflow}
\label{fig:sequence diagram of the CI/CD workflow}
\end{figure}

\subsection{CI/CD workflow steps }

\subsubsection{Architecture of the software under development }

Among the proprietary software developed by the company, we have “SYSTNAPS” which is used for data processing by a few well known companies such as “Dassault-Systems” and others. It is mainly composed of three major parts as shown in the diagram below : 

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f47.png}
\caption{Architecture of the software under development}
\label{fig:Architecture of the software under development}
\end{figure}

The backend api interacts with the frontend by providing the implemented computing functions. It also uses a utility api which uses puppeteer and various other libraries for graph rendering. Both relational and document databases are used for data storage. Some of the data is stored in document format in an S3 compatible storage backend.

\subsubsection{Containerizing artifacts:}

Container images for the application components are built inside the docker in docker instance we have previously build. It is configured to be able to authenticate with the private registry to pull the base image and push the resulting artifact. 

\subsubsubsection{Dockerfile of the backend API container image }

For building the container image for the backend api, we first build a base image which contains most of the packages and immutable config. 

The resulting dockerfile for the actual container image is as follows: 

\begin{listing}[H]
    \inputminted[firstline=1,lastline=30]{Dockerfile}{codeListing/syst_backend_Dockerfile}
\end{listing}
\begin{listing}[H]
     \inputminted[firstline=31]{Dockerfile}{codeListing/syst_backend_Dockerfile}
    \caption{Backend API Dockerfile}
    \label{lst:API Dockerfile}
\end{listing}
 

\subsubsubsection{Dockerfile of the frontend container image }

As with the backend part, this image is built from a base that contains all that is immutable. Building the frontend part of the application is done in two stages as follows: 

 \begin{listing}[H]
    \inputminted{Dockerfile}{codeListing/syst_frontend_Dockerfile}
    \caption{Frontend Dockerfile}
    \label{lst:Dind Dockerfile}
\end{listing}

\subsubsubsection{Dockerfile of the utility API container image} 

 
\subsubsection{Code quality }

\subsubsubsection{Conceptual design }

To ensure code quality, the first step is to scan the developed code of both the frontend, backend and utility for vulnerabilities and other irregularities.  

A quality gate is then used to inform the cicd orchestrator of the level of stability. The following diagram showcases the involved processes of this stage: 

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f47.png}
\caption{ Conceptual design of Code quality }
\label{fig:conceptual design of Code quality }
\end{figure}


\subsubsubsection{Implementation }

As illustrated in this figure, the code scanning process is initiated by our orchestrator following each accepted merge request in the SCM. The following is the pipeline for the scan job: 

 
\begin{listing}[H]
    \inputminted{Dockerfile}{codeListing/Jenkinsfile_scan}
    \caption{ Jenkins file scan}
    \label{lst:jenkinsfile_scan}
\end{listing}
 

\subsubsection{Building artifacts: }

\subsubsubsection{Conceptual design :}

Containerizing the applications contributes to portability, consistency, and resource efficiency of the workloads to be deployed. Following each approved merge request, a build step is processed. 

The following diagram illustrates this process and the interaction between the key components: 

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f48.png}
\caption{Conceptual design of building artifact }
\label{fig:Conceptual design of building artifact }
\end{figure}

\subsubsubsection{Implementation :}

In similar fashion to the code scanning step, building artifacts is initiated following each approved merge request. A webhook is sent by the SCM tool to Jenkins which starts the job using the following pipeline: 

\begin{listing}[H]
    \inputminted[firstline=1,lastline=40]{Dockerfile}{codeListing/Jenkinsfile_build}
\end{listing}

\begin{listing}[H]
    \inputminted[firstline=41,lastline=75]{Dockerfile}{codeListing/Jenkinsfile_build}
\end{listing}

\begin{listing}[H]
    \inputminted[firstline=76]{Dockerfile}{codeListing/Jenkinsfile_build}
    \caption{Jenkins build}
    \label{lst:jenkinsfile_build}
\end{listing}

The build and publish steps are processed in a DinD agent spun inside the Kubernetes cluster. The agent is provided with the necessary credentials to authenticate with the private registry as well as a persistent volume in which it stores the cache data of image layers. 

For each build process, the name and tag of the image are programmatically extracted both from the respective repository name in the SCM and the release tag. 

 

\subsubsection{Delivering artifacts }

\subsubsubsection{Conceptual design:}

For delivering artifacts, the CI/CD orchestrator, Jenkins, is used in conjunction with argocd, our CD/CD controller. ArgoCD uses deployment manifests pushed to the SCM in order to create the workload objects. 

The product delivery process is initiated in any of these cases depending on the rollout strategy: 

\begin{itemize}[label={--}]
\item A release tag is pushed to the SCM. 
\item A newer container image with the same tag is pushed to \item the private registry. 
\end{itemize}

An update to the manifests is pushed to the SCM. 

The following is a general diagram of the delivery process: 

\begin{figure}[H]\centering
\includegraphics[width=1.0\textwidth,angle=00]{assets/f49.png}
\caption{Conceptual design of Delivering artifacts }
\label{fig:Conceptual design of Delivering artifacts }
\end{figure}

\subsubsubsection{Implementation: }

The deployment manifests, configmaps, secrets, ingressroutes and other Kubernetes objects needed for deploying the applications are templated with each delivery using ytt. This makes the container configuration reusable and extensible.  


\paragraph{Overview: }

The following is an overview of the declarative Jenkinsfile used : 

 
\begin{listing}[H]
    \inputminted[firstline=1,lastline=30]{Dockerfile}{codeListing/Jenkinsfile_deploy_overview}
\end{listing}
 
\begin{listing}[H]
    \inputminted[firstline=31]{Dockerfile}{codeListing/Jenkinsfile_deploy_overview}
    \caption{jenkins deploy overview}
    \label{lst:jenkinsfile_deploy_overview}
\end{listing}

\paragraph{Templating manifests: }

Using ytt from Carvel, we are able to create Kubernetes manifests in the YAML format using a specific variable schema. As shown in the stage below, reusable templates are first pulled from the SCM, templated using ytt, and then pushed to an SCM repository in a secure manner: 

 \begin{listing}[H]
    \inputminted[firstline=1,lastline=15]{Dockerfile}{codeListing/Jenkinsfile_deploy_templating}
\end{listing}

 \begin{listing}[H]
    \inputminted[firstline=16,lastline=49]{Dockerfile}{codeListing/Jenkinsfile_deploy_templating}
\end{listing}

 \begin{listing}[H]
    \inputminted[firstline=50]{Dockerfile}{codeListing/Jenkinsfile_deploy_templating}
    \caption{Jenkins deploy templating}
    \label{lst:jenkinsfile_deploy_templating}
\end{listing}


 
\paragraph{Delivering workloads: }

Once the deployment manifests are present in the SCM repository, Jenkins then informs argocd to begin the delivery process. The following is the declarative stage used: 

\begin{listing}[H]
    \inputminted[firstline=1,lastline=10]{Dockerfile}{codeListing/Jenkinsfile_deploy_delivery}
\end{listing}

\begin{listing}[H]
    \inputminted[firstline=11,lastline=45]{Dockerfile}{codeListing/Jenkinsfile_deploy_delivery}
\end{listing}

\begin{listing}[H]
    \inputminted[firstline=46]{Dockerfile}{codeListing/Jenkinsfile_deploy_delivery}
    \caption{Jenkins deploy delivery}
    \label{lst:jenkinsfile_deploy_delivery}
\end{listing}